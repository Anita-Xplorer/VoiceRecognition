{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10329,"status":"ok","timestamp":1745315714119,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"auA6Rp1Mab-W","outputId":"866a9031-d877-4c50-ea13-27757943f60b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install librosa scikit-learn tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5966,"status":"ok","timestamp":1745315730078,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"_SPSlau3fDFQ","outputId":"d5ffc292-b94d-43a6-87b0-0bb69e719915"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"]}],"source":["!pip install soundfile"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YzXFv07Np3J","executionInfo":{"status":"ok","timestamp":1745315788230,"user_tz":-330,"elapsed":27080,"user":{"displayName":"Labproject","userId":"02962465902672505605"}},"outputId":"e5bc20dc-c2e2-4e89-a1c6-e8bd8f9273fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IxDluEMCa2SP","executionInfo":{"status":"ok","timestamp":1745315803416,"user_tz":-330,"elapsed":9474,"user":{"displayName":"Labproject","userId":"02962465902672505605"}}},"outputs":[],"source":["import os\n","import librosa\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TKJUKuh0a42X","executionInfo":{"status":"ok","timestamp":1745315806896,"user_tz":-330,"elapsed":16,"user":{"displayName":"Labproject","userId":"02962465902672505605"}}},"outputs":[],"source":["def extract_mfcc(file_path):\n","    # Load the audio file\n","    audio, sr = librosa.load(file_path, sr=None)\n","    # Extract MFCC features\n","    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n","    mfcc = np.mean(mfcc.T, axis=0)  # Taking the mean of MFCC features over time\n","    return mfcc\n","\n","def load_data(data_dir):\n","    features = []\n","    labels = []\n","\n","    # Iterate over each folder in the data directory\n","    for speaker in os.listdir(data_dir):\n","        speaker_path = os.path.join(data_dir, speaker)\n","        if os.path.isdir(speaker_path):\n","            for file in os.listdir(speaker_path):\n","                file_path = os.path.join(speaker_path, file)\n","                if file_path.endswith('.wav'):  # Only process .wav files\n","                    mfcc = extract_mfcc(file_path)\n","                    features.append(mfcc)\n","                    labels.append(speaker)\n","\n","    return np.array(features), np.array(labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"executionInfo":{"elapsed":3913,"status":"error","timestamp":1745316138663,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"0ErjjGupbZIO","outputId":"3da8202a-2a87-48c7-cc84-c1db4958d2b9"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4c632361e853>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/drive/MyDrive/archive/50_speakers_audio_data'\u001b[0m  \u001b[0;31m# Replace with your folder path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Encode the labels (speaker names) into numerical values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-f60aff50ae1f>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only process .wav files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-f60aff50ae1f>\u001b[0m in \u001b[0;36mextract_mfcc\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Extract MFCC features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Taking the mean of MFCC features over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[0m\n\u001b[1;32m   1991\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m         \u001b[0;31m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     \u001b[0mfft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fftlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2133\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Mel-frequency spectrogram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m     \"\"\"\n\u001b[0;32m-> 2135\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   2136\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         S = (\n\u001b[1;32m   2944\u001b[0m             np.abs(\n\u001b[0;32m-> 2945\u001b[0;31m                 stft(\n\u001b[0m\u001b[1;32m   2946\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mbl_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         stft_matrix[..., bl_s + off_start : bl_t + off_start] = fft.rfft(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mfft_window\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_backend.py\u001b[0m in \u001b[0;36m__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_basic_backend.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     72\u001b[0m def rfft(x, n=None, axis=-1, norm=None,\n\u001b[1;32m     73\u001b[0m          overwrite_x=False, workers=None, *, plan=None):\n\u001b[0;32m---> 74\u001b[0;31m     return _execute_1D('rfft', _pocketfft.rfft, x, n=n, axis=axis, norm=norm,\n\u001b[0m\u001b[1;32m     75\u001b[0m                        overwrite_x=overwrite_x, workers=workers, plan=plan)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_basic_backend.py\u001b[0m in \u001b[0;36m_execute_1D\u001b[0;34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         return pocketfft_func(x, n=n, axis=axis, norm=norm,\n\u001b[0m\u001b[1;32m     30\u001b[0m                               overwrite_x=overwrite_x, workers=workers, plan=plan)\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/fft/_pocketfft/basic.py\u001b[0m in \u001b[0;36mr2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Note: overwrite_x is not utilised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Load the data\n","data_dir = r'/content/drive/MyDrive/archive/50_speakers_audio_data'  # Replace with your folder path\n","X, y = load_data(data_dir)\n","\n","# Encode the labels (speaker names) into numerical values\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":8,"status":"error","timestamp":1745316128448,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"kp67FIMhbdA7","outputId":"034f3a79-5ed3-42e2-d6aa-40721578e191"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6f0d81790684>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# SVM Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}],"source":["# SVM Classifier\n","svm_classifier = SVC(kernel='linear', probability=True)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5746,"status":"ok","timestamp":1744961430214,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"QCTzTTl-b7sY","outputId":"54d2416b-7211-4160-aaca-955c2a59f6ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.0435 - loss: 19.7177 - val_accuracy: 0.1930 - val_loss: 4.1787\n","Epoch 2/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2756 - loss: 3.3023 - val_accuracy: 0.4094 - val_loss: 2.4354\n","Epoch 3/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4629 - loss: 2.1916 - val_accuracy: 0.6179 - val_loss: 1.7622\n","Epoch 4/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 1.6124 - val_accuracy: 0.6589 - val_loss: 1.4542\n","Epoch 5/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 1.1658 - val_accuracy: 0.7739 - val_loss: 1.1250\n","Epoch 6/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 0.9018 - val_accuracy: 0.8090 - val_loss: 0.9821\n","Epoch 7/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.7359 - val_accuracy: 0.7934 - val_loss: 0.9823\n","Epoch 8/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.6954 - val_accuracy: 0.8850 - val_loss: 0.7845\n","Epoch 9/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.4799 - val_accuracy: 0.8772 - val_loss: 0.8042\n","Epoch 10/10\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.4115 - val_accuracy: 0.9045 - val_loss: 0.6350\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.5406 \n","Test Accuracy: 90.45%\n"]}],"source":["##   FOR LARGE DATASETS\n","# Build a simple neural network model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(len(np.unique(y_encoded)), activation='softmax')  # Output layer with one neuron per class\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":754,"status":"ok","timestamp":1744961439244,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"C-iA8Lf3b_Fj","outputId":"5c7d02be-f899-43f1-e38a-4f2a89b7ed4a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n","Predicted speaker: karuna\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/karuna/Karuna3.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":455,"status":"ok","timestamp":1744961444610,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"feKU9MPqceer","outputId":"cfb8be9f-ea9e-4f3a-cf44-36ba96075f6a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","Predicted speaker: swayam\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/swayam/swayam7.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1744961448877,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"PHyCITlZzTr3","outputId":"21ab17a3-8867-4f04-ee19-630724b6b32d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","Predicted speaker: anita\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/anita/ani12.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1744961476324,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"vdm0QFb8TDNL","outputId":"e351ec47-9ee1-4226-d196-d0d161f69e81"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n","Predicted speaker: anita\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/anita/ani9.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":544,"status":"ok","timestamp":1744961481532,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"9_jWtb8dTJW9","outputId":"c60b1538-f289-4804-fd06-a514c38c82f4"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","Predicted speaker: alok\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/alok/alok5.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1052,"status":"ok","timestamp":1744961541070,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"r0SLJgYcvVb-","outputId":"90a6cfca-c2f4-4f98-f9c5-0fbffb9c3eb9"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n","Predicted speaker: anita\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/anita/ani9.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1116,"status":"ok","timestamp":1744961588553,"user":{"displayName":"Labproject","userId":"02962465902672505605"},"user_tz":-330},"id":"0AlFvxRtvzjM","outputId":"3828849e-843d-4605-bb6a-dfdd2b333403"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-f60aff50ae1f>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio, sr = librosa.load(file_path, sr=None)\n","/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","Predicted speaker: anita\n"]}],"source":["def predict_speaker(file_path, model=None):\n","    mfcc = extract_mfcc(file_path).reshape(1, -1)  # Reshape for prediction\n","    if model:\n","        prediction = model.predict(mfcc)\n","        # Get the class with the highest probability\n","        predicted_class_index = np.argmax(prediction, axis=1)\n","        # Inverse transform the predicted class index\n","        speaker = label_encoder.inverse_transform(predicted_class_index)[0]\n","    else:\n","        prediction = svm_classifier.predict(mfcc)\n","        speaker = label_encoder.inverse_transform([prediction])[0]\n","    return speaker\n","\n","# Example usage\n","test_file = '/content/drive/MyDrive/archive/50_speakers_audio_data/anita/ani12.wav'  # Replace with your test file path\n","predicted_speaker = predict_speaker(test_file, model=model)\n","print(f\"Predicted speaker: {predicted_speaker}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SZCZYalwpKp"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}